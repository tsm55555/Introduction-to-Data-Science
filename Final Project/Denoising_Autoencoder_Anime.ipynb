{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6weXs18VQCf5"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3nO5GQLQL-R"
   },
   "source": [
    "Upload the Anime images dataset and unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_0H7fd2Pcbx",
    "outputId": "a263f5ea-2e3b-4012-91d4-bd0b98c51a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-01 20:26:46--  http://www.nurs.or.jp/~nagadomi/animeface-character-dataset/data/animeface-character-dataset.zip\n",
      "Resolving www.nurs.or.jp... 54.187.126.238\n",
      "Connecting to www.nurs.or.jp|54.187.126.238|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 592335393 (565M) [application/zip]\n",
      "Saving to: ‘animeface-character-dataset.zip’\n",
      "\n",
      "animeface-character 100%[===================>] 564.89M  8.74MB/s    in 71s     \n",
      "\n",
      "2022-01-01 20:27:57 (7.98 MB/s) - ‘animeface-character-dataset.zip’ saved [592335393/592335393]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.nurs.or.jp/~nagadomi/animeface-character-dataset/data/animeface-character-dataset.zip\n",
    "!unzip -qq animeface-character-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTAOrGqLQQjq"
   },
   "source": [
    "Split dataset into test, validation and train data set of images, resizing images into 64x64 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noh6weCbPvLT"
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_val = []\n",
    "x_test = []\n",
    "\n",
    "directories = os.listdir('/home/tsm62803/my_code/animefaces256cleaner')\n",
    "for directory in directories:\n",
    "  dir_path = '/home/tsm62803/my_code/animefaces256cleaner'+directory\n",
    "  num_fil = 0\n",
    "  num_train = 0\n",
    "  num_val = 0\n",
    "  num_test = 0\n",
    "  if os.path.isdir(dir_path):\n",
    "    for filename in os.listdir(dir_path):\n",
    "      if filename.endswith(\".png\"):\n",
    "        num_fil += 1\n",
    "    num_train = int(round(num_fil*0.7))\n",
    "    num_val = int(round((num_fil-num_train)*0.5))\n",
    "    num_test = int(round(num_fil-num_train-num_val))\n",
    "    i = 0\n",
    "    for filename in os.listdir(dir_path):\n",
    "      if filename.endswith(\".png\"):\n",
    "        filepath = dir_path+\"/\"+filename\n",
    "        if i<num_train:\n",
    "          img = cv2.imread(filepath, 1)\n",
    "          img = cv2.resize(img, (64,64))\n",
    "          img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "          x_train.append(img)\n",
    "        elif i<(num_train+num_val):\n",
    "          img = cv2.imread(filepath, 1)\n",
    "          img = cv2.resize(img, (64,64))\n",
    "          img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "          x_val.append(img)\n",
    "        elif i<(num_train+num_val+num_train):\n",
    "          img = cv2.imread(filepath, 1)\n",
    "          img = cv2.resize(img, (64,64))\n",
    "          img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "          x_test.append(img)\n",
    "        i += 1\n",
    "x_train = np.array(x_train)\n",
    "x_val = np.array(x_val)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppZ_p8PBQURq"
   },
   "source": [
    "This is example of images in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "7TPhjsDYQH5q",
    "outputId": "eba0190f-4982-4804-f3de-e0eb92524cea"
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x_train[0])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(x_val[10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8rPdp4Zgt_V"
   },
   "source": [
    "Data normalization to values in range [0-1] and reshape to array suitable for network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPWq1sD6grdt"
   },
   "outputs": [],
   "source": [
    "max_value = float(x_train.max())\n",
    "x_train = x_train.astype('float32') / max_value\n",
    "x_val = x_val.astype('float32') / max_value\n",
    "x_test = x_test.astype('float32') / max_value\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train), 64, 64, 3))\n",
    "x_val = np.reshape(x_val, (len(x_val), 64, 64, 3))\n",
    "x_test = np.reshape(x_test, (len(x_test), 64, 64, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vx39-F2igyOd"
   },
   "source": [
    "Applying noise to images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JtrYB5c3gyVn"
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.3\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_val_noisy = x_val + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_val.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_val_noisy = np.clip(x_val_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRMbp3pHg39k"
   },
   "source": [
    "That is how the first 6 noisy data images looks like\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "XEb5F_HYg4G9",
    "outputId": "53a19b2a-f3e8-41dd-f7e2-cb7ae03d43e7"
   },
   "outputs": [],
   "source": [
    "n = 7\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1,n):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_train_noisy[i].reshape(64, 64, 3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm_bTj5FhFP2"
   },
   "source": [
    "We use similar convolutional autoencoder model as with the MNIST dataset, but now with 3 channels for RGB images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gr3xmvighFXe"
   },
   "outputs": [],
   "source": [
    "input_img = Input(shape=(64, 64, 3))  # shape of the images that wil be on input\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iied8r0LhQTO"
   },
   "source": [
    "Train network for 100 epochs with noisy images as input and correct images as desired output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPOBf8cFhQj1"
   },
   "outputs": [],
   "source": [
    "log = autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=500,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val_noisy, x_val),\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "6MUaOUHQhW6B",
    "outputId": "0a1a6693-01fc-4910-ce72-fa2bbb53cbfc"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "[plt.plot(v,label=str(k)) for k,v in log.history.items()]\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLZfCXUjhbbm"
   },
   "source": [
    "Testing the denoising autoencoder and visualizing input images and output reconstruction of autoencoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "f4R66gBhhbiL",
    "outputId": "859aa5a8-e6b1-41b3-b823-6fb4b9fd7652"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
    "n = 1\n",
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(1,n):\n",
    "    r = random.randint(0,2173)\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i)\n",
    "    plt.imshow(x_test[r].reshape(64, 64, 3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # display noisy\n",
    "    ax = plt.subplot(3, n, i+n)\n",
    "    plt.imshow(x_test_noisy[r].reshape(64, 64, 3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i+n + n)\n",
    "    plt.imshow(decoded_imgs[r].reshape(64, 64, 3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPkRMipfjajz"
   },
   "source": [
    "# Inpainting images - stripes\n",
    "As before, we test denoising autoencoder for inpainting, so we apply into images randomly stripes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpg1suR9jbwk"
   },
   "outputs": [],
   "source": [
    "stripes_no = 24\n",
    "x_train_inpaint = copy.deepcopy(x_train)\n",
    "x_val_inpaint = copy.deepcopy(x_val)\n",
    "x_test_inpaint = copy.deepcopy(x_test)\n",
    "for i in range(len(x_train_inpaint)):\n",
    "    stripes = random.sample(range(64), stripes_no)\n",
    "    for j in range(len(x_train_inpaint[i])):\n",
    "        if j in stripes:\n",
    "            x_train_inpaint[i][j] = np.zeros((64,1))\n",
    "            \n",
    "for i in range(len(x_val_inpaint)):\n",
    "    stripes = random.sample(range(64), stripes_no)\n",
    "    for j in range(len(x_val_inpaint[i])):\n",
    "        if j in stripes:\n",
    "            x_val_inpaint[i][j] = np.zeros((64,1))\n",
    "\n",
    "for i in range(len(x_test_inpaint)):\n",
    "    stripes = random.sample(range(64), stripes_no)\n",
    "    for j in range(len(x_test_inpaint[i])):\n",
    "        if j in stripes:\n",
    "            x_test_inpaint[i][j] = np.zeros((64,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BrEAnTEjldj"
   },
   "source": [
    "Visualizing input images with stripes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "id": "8kHfuZJVjlmr",
    "outputId": "bef8e16f-be01-42ce-d912-3c5c8efb3f1b"
   },
   "outputs": [],
   "source": [
    "n = 7\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1,n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_train_inpaint[i].reshape(64, 64, 3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5SVcTGYjpSq"
   },
   "source": [
    "Fit into the same network model once again but know the images with stripes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxhxGk0Gjpuh"
   },
   "outputs": [],
   "source": [
    "log = autoencoder.fit(x_train_inpaint, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val_inpaint, x_val),\n",
    "                verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMYamLYCj4HS"
   },
   "source": [
    "Learning loss curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "iaWjauRQj4gK",
    "outputId": "85a07eb4-a70b-4d1d-e4f8-182c69c6fc08"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "[plt.plot(v,label=str(k)) for k,v in log.history.items()]\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuKjAR0Vj50X"
   },
   "source": [
    "Now tests and visualization of reconstructed images. Displayed in order: original image, image with stripes, reconstructed image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "VM2c8daHj59a",
    "outputId": "1a4e74fa-8fbd-4fe6-d250-7d04ad56d49b"
   },
   "outputs": [],
   "source": [
    "decoded_imgs_inpaint = autoencoder.predict(x_test_inpaint)\n",
    "n = 7\n",
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(1,n):\n",
    "    r = random.randint(0,2173)\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i)\n",
    "    plt.imshow(x_test[r].reshape(64, 64, 3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # display noisy\n",
    "    ax = plt.subplot(3, n, i+n)\n",
    "    plt.imshow(x_test_inpaint[r].reshape(64, 64, 3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i +n+ n)\n",
    "    plt.imshow(decoded_imgs_inpaint[r].reshape(64, 64, 3))\n",
    "    \n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-ATs6sJj_bz"
   },
   "source": [
    "# Inpainting - blocks\n",
    "Creating data from dataset images with randomly placed gray block of size 24x24\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4yMJZN0kDiD"
   },
   "outputs": [],
   "source": [
    "block_size = 24\n",
    "x_train_inpaint_block = copy.deepcopy(x_train)\n",
    "x_val_inpaint_block = copy.deepcopy(x_val)\n",
    "x_test_inpaint_block = copy.deepcopy(x_test)\n",
    "for i in range(len(x_train_inpaint_block)):\n",
    "    x = random.randint(0,64-block_size)\n",
    "    y = random.randint(0,64-block_size)\n",
    "    for j in range(block_size):\n",
    "        for k in range(block_size):\n",
    "            x_train_inpaint_block[i][x+j][y+k] = 0.5 # gray color\n",
    "            \n",
    "for i in range(len(x_val_inpaint_block)):\n",
    "    x = random.randint(0,64-block_size)\n",
    "    y = random.randint(0,64-block_size)\n",
    "    for j in range(block_size):\n",
    "        for k in range(block_size):\n",
    "            x_val_inpaint_block[i][x+j][y+k] = 0.5 \n",
    "\n",
    "for i in range(len(x_test_inpaint_block)):\n",
    "    x = random.randint(0,64-block_size)\n",
    "    y = random.randint(0,64-block_size)\n",
    "    for j in range(block_size):\n",
    "        for k in range(block_size):\n",
    "            x_test_inpaint_block[i][x+j][y+k] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0FoROfckETT"
   },
   "source": [
    "Visualizing input images with random gray blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "id": "nQbFDM0xkGZ8",
    "outputId": "45392c2e-df23-4a19-96c9-e12027159c51"
   },
   "outputs": [],
   "source": [
    "n = 7\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1,n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_train_inpaint_block[i].reshape(64, 64, 3))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8M6Jn7MykG4m"
   },
   "source": [
    "Fit into the same network model once again but know with the images with grayblocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwQW8Kj2kH_l"
   },
   "outputs": [],
   "source": [
    "log = autoencoder.fit(x_train_inpaint_block, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val_inpaint_block, x_val),\n",
    "               verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8LKIPlkkJPr"
   },
   "source": [
    "Learning loss curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "g0a2HYlGkMg9",
    "outputId": "bfa9e4a8-47b7-4d15-d048-d155ee04bbd3"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "[plt.plot(v,label=str(k)) for k,v in log.history.items()]\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQY2Dx4WkP8U"
   },
   "source": [
    "Now tests and visualization of reconstructed images. Displayed in order: original image, image with gray blocks, reconstructed image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "6CIBRQiqkMmm",
    "outputId": "5df8fd95-f5f7-4705-baf6-5ebe30327de6"
   },
   "outputs": [],
   "source": [
    "decoded_imgs_inpaint_block = autoencoder.predict(x_test_inpaint_block)\n",
    "n = 7\n",
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(1,n):\n",
    "    r = random.randint(0,2173)\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i)\n",
    "    plt.imshow(x_test[r].reshape(64, 64, 3))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # display noisy\n",
    "    ax = plt.subplot(3, n, i+n)\n",
    "    plt.imshow(x_test_inpaint_block[r].reshape(64, 64, 3))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, n, i + n + n)\n",
    "    plt.imshow(decoded_imgs_inpaint_block[r].reshape(64, 64, 3))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdgloxrMHjQf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Denoising Autoencoder Anime.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
