{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "Autoencoder are special type of deep learning architecture that consist of two networks encoder and decoder.\n",
    "The encoder, through a series of CNN and downsampling, learns a reduced dimensional representation of the input data while decoder  through the use of CNN and upsampling, attempts to regenerate the data from the these representations. A well-trained decoder is able to regenerated data that is identical or as close as possible to the original input data.\n",
    "Autoencoder are generally used for anamoly detection, denoising image, colorizing the images. Here, i am going to colorize the landscape images using autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://miro.medium.com/max/600/1*nqzWupxC60iAH2dYrFT78Q.png' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Colorization\n",
    "Image colorization using different softwares require large amount of human effort, time and skill.But special type of deep learning architecture called autoencoder has made this task quiet easy. Automatic image colorization often involves the use of a class of convolutional neural networks (CNN) called autoencoders. These neural networks are able to distill the salient features of an image, and then regenerate the image based on these learned features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/LYSAOD3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "from keras.layers import MaxPool2D,Conv2D,UpSampling2D,Input,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting landscape image data,resizing them and appending in array\n",
    "To get the image in sorted order i have defined the function sorted_alphanumeric. Here, I have used open cv library to read and resize images. Finally images are normalized and are converted to array and are appended in empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the files in proper order\n",
    "def sorted_alphanumeric(data):  \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n",
    "    return sorted(data,key = alphanum_key)\n",
    "# defining the size of the image\n",
    "SIZE = 160\n",
    "color_img = []\n",
    "path = '/home/tsm62803/my_code/Dataset/landscape'\n",
    "files = os.listdir(path)\n",
    "files = sorted_alphanumeric(files)\n",
    "count = 0\n",
    "for i in tqdm(files):\n",
    "    if count == 20000:\n",
    "        break\n",
    "    else:    \n",
    "        count += 1 \n",
    "        img = cv2.imread(path + '/'+i,1)\n",
    "        # open cv reads images in BGR format so we have to convert it to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #resizing image\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        color_img.append(img_to_array(img))\n",
    "\n",
    "\n",
    "gray_img = []\n",
    "path = '/home/tsm62803/my_code/Dataset/landscape'\n",
    "files = os.listdir(path)\n",
    "files = sorted_alphanumeric(files)\n",
    "count = 0\n",
    "for i in tqdm(files):\n",
    "     if count == 20000:\n",
    "        break\n",
    "     else: \n",
    "        count += 1\n",
    "        img = cv2.imread(path + '/'+i,1)\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #resizing image\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = img.astype('float32') / 255.0\n",
    "#         noise_factor = 0.3 # add noise\n",
    "#         img = img + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=img.shape) # add noise\n",
    "#         img = np.clip(img, 0., 1.) # add noise\n",
    "        gray_img.append(img_to_array(img))\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Color image and it's corresponding grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function to plot images pair\n",
    "def plot_images(color,grayscale):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('Color Image', color = 'green', fontsize = 20)\n",
    "    plt.imshow(color)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('Grayscale Image ', color = 'black', fontsize = 20)\n",
    "    plt.imshow(grayscale,cmap='gray') # for grayscale images\n",
    "    #plt.imshow(grayscale) # for color images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting image pair**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500,503):\n",
    "     plot_images(color_img[i],gray_img[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing and reshaping\n",
    "Out of 5000 images I have sliced them to two part. train images consist 4000 images  while test images contains 1000 images.\n",
    "After slicing the image array, I reshaped them so that images can be fed directly into our encoder network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gray_image = gray_img[:4000 ]\n",
    "train_color_image = color_img[:4000 ]\n",
    "\n",
    "test_gray_image = gray_img[4000: ]\n",
    "test_color_image = color_img[4000: ]\n",
    "# reshaping\n",
    "train_g = np.reshape(train_gray_image,(len(train_gray_image),SIZE,SIZE,1))\n",
    "train_c = np.reshape(train_color_image, (len(train_color_image),SIZE,SIZE,3))\n",
    "print('Train color image shape:',train_c.shape)\n",
    "\n",
    "\n",
    "test_gray_image = np.reshape(test_gray_image,(len(test_gray_image),SIZE,SIZE,1))\n",
    "test_color_image = np.reshape(test_color_image, (len(test_color_image),SIZE,SIZE,3))\n",
    "print('Test color image shape',test_color_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definie the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "def down(filters , kernel_size, apply_batch_normalization = True):\n",
    "    downsample = tf.keras.models.Sequential()\n",
    "    downsample.add(layers.Conv2D(filters,kernel_size,padding = 'same', strides = 2))\n",
    "    if apply_batch_normalization:\n",
    "        downsample.add(layers.BatchNormalization())\n",
    "    downsample.add(keras.layers.LeakyReLU())\n",
    "    return downsample\n",
    "\n",
    "\n",
    "def up(filters, kernel_size, dropout = False):\n",
    "    upsample = tf.keras.models.Sequential()\n",
    "    upsample.add(layers.Conv2DTranspose(filters, kernel_size,padding = 'same', strides = 2))\n",
    "    if dropout:\n",
    "        upsample.dropout(0.2)\n",
    "    upsample.add(keras.layers.LeakyReLU())\n",
    "    return upsample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    #inputs = layers.Input(shape= [160,160,3]) # for color images\n",
    "    inputs = layers.Input(shape= [160,160,3]) # for colorization\n",
    "    d1 = down(128,(3,3),False)(inputs)\n",
    "    d2 = down(128,(3,3),False)(d1)\n",
    "    d3 = down(256,(3,3),True)(d2)\n",
    "    d4 = down(512,(3,3),True)(d3)\n",
    "    \n",
    "    d5 = down(512,(3,3),True)(d4)\n",
    "    #upsampling\n",
    "    u1 = up(512,(3,3),False)(d5)\n",
    "    u1 = layers.concatenate([u1,d4])\n",
    "    u2 = up(256,(3,3),False)(u1)\n",
    "    u2 = layers.concatenate([u2,d3])\n",
    "    u3 = up(128,(3,3),False)(u2)\n",
    "    u3 = layers.concatenate([u3,d2])\n",
    "    u4 = up(128,(3,3),False)(u3)\n",
    "    u4 = layers.concatenate([u4,d1])\n",
    "    u5 = up(3,(3,3),False)(u4)\n",
    "    u5 = layers.concatenate([u5,inputs])\n",
    "    output = layers.Conv2D(3,(2,2),strides = 1, padding = 'same')(u5)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a new model\n",
    "model = model()\n",
    "\n",
    "# load checkpoint\n",
    "# checkpoint_path = \"/home/tsm62803/my_code/final project checkpoints/anime/de-noise\" + \"/cp.ckpt\"\n",
    "# model.load_weights(checkpoint_path)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/tsm62803/my_code/final project checkpoints/landscape\" + \"/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.fit(train_g, train_c, epochs = 50, batch_size = 256,verbose = 1, shuffle=True, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_gray_image,test_color_image, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting colorized image along with grayscale and color image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load checkpoint\n",
    "checkpoint_path = \"/home/tsm62803/my_code/final project checkpoints/anime/de-noise 500\" + \"/cp.ckpt\"\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# defining function to plot images pair\n",
    "def plot_images(color,grayscale,predicted, training_or_testing):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('Original Image', color = 'green', fontsize = 20)\n",
    "    plt.imshow(color)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('Grayscale Image ', color = 'black', fontsize = 20)\n",
    "    plt.imshow(grayscale, cmap='gray')\n",
    "    plt.subplot(1,3,3)\n",
    "    #plt.title('colorized Image ', color = 'Red', fontsize = 20)\n",
    "    plt.title('De-noised Image ', color = 'Red', fontsize = 20)\n",
    "    plt.imshow(predicted)\n",
    "    if training_or_testing == 0:\n",
    "        plt.savefig(\"/home/tsm62803/my_code/Introduction-to-Data-Science/Final Project/results/de-noise/500 epoch/training set/\" + str(count), bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(\"/home/tsm62803/my_code/Introduction-to-Data-Science/Final Project/results/de-noise/500 epoch/testing set/\" + str(count), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Training set performance\")\n",
    "for i in range(1050,1060):\n",
    "    count = i\n",
    "    predicted = np.clip(model.predict(train_gray_image[i].reshape(1,SIZE, SIZE,1)),0.0,1.0).reshape(SIZE, SIZE,3)\n",
    "    plot_images(train_color_image[i],train_gray_image[i],predicted, 0)\n",
    "\n",
    "print(\"Testing set performance\")\n",
    "for i in range(1000,1010):\n",
    "    count = i\n",
    "    predicted = np.clip(model.predict(test_gray_image[i].reshape(1,SIZE, SIZE,1)),0.0,1.0).reshape(SIZE, SIZE,3)\n",
    "    plot_images(test_color_image[i],test_gray_image[i],predicted, 1)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load checkpoint\n",
    "checkpoint_path = \"/home/tsm62803/my_code/final project checkpoints/anime/de-noise 500\" + \"/cp.ckpt\"\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# defining function to plot images pair\n",
    "def plot_images(color,grayscale,predicted):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('Original Image', color = 'green', fontsize = 20)\n",
    "    plt.imshow(color)\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1,3,2)\n",
    "#     plt.title('Grayscale Image ', color = 'black', fontsize = 20)\n",
    "#     plt.imshow(grayscale, cmap='gray')\n",
    "#     #plt.axis(\"off\")\n",
    "#     plt.subplot(1,3,3)\n",
    "    plt.title('Colorized Image ', color = 'Red', fontsize = 20)\n",
    "    #plt.title('De-noised Image ', color = 'Red', fontsize = 20)\n",
    "    plt.imshow(predicted)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "SIZE = 160\n",
    "color_img = []\n",
    "path = \"/home/tsm62803/my_code/Dataset/animefaces256cleaner/18556684_result.jpg\"\n",
    "img = cv2.imread(path)\n",
    "# open cv reads images in BGR format so we have to convert it to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#resizing image\n",
    "img = cv2.resize(img, (SIZE, SIZE))\n",
    "img = img.astype('float32') / 255.0\n",
    "color_img.append(img_to_array(img))\n",
    "\n",
    "\n",
    "gray_img = []\n",
    " \n",
    "img = cv2.imread(path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#resizing image\n",
    "img = cv2.resize(img, (SIZE, SIZE))\n",
    "img = img.astype('float32') / 255.0\n",
    "gray_img.append(img_to_array(img))\n",
    "         \n",
    "\n",
    "predicted = np.clip(model.predict(gray_img[0].reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)\n",
    "plot_images(color_img[0],gray_img[0],predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = []\n",
    " \n",
    "img = cv2.imread(\"/home/tsm62803/my_code/Introduction-to-Data-Science/10090845_result.jpg\")\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "ksize = (10, 10)\n",
    "img = cv2.blur(img, ksize) \n",
    "#resizing image\n",
    "img = cv2.resize(img, (SIZE, SIZE))\n",
    "img = img.astype('float32') / 255.0\n",
    "gray_img.append(img_to_array(img))\n",
    "\n",
    "# defining function to plot images pair\n",
    "def plot_images(grayscale):\n",
    "    #plt.title('Grayscale Image ', color = 'black', fontsize = 20)\n",
    "    plt.imshow(grayscale,cmap='gray') # for grayscale images\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_images(gray_img[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38_tensorflow]",
   "language": "python",
   "name": "conda-env-py38_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
